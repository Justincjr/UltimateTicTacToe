{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd02289",
   "metadata": {},
   "source": [
    "data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5229c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from utils import State, load_data\n",
    "from collections import OrderedDict\n",
    "\n",
    "def update_prev_local_action(prev: tuple, transform: str) -> tuple:\n",
    "    r, c = prev\n",
    "    if transform == \"identity\":\n",
    "        return (r, c)\n",
    "    elif transform == \"horizontal\":\n",
    "        return (r, 2 - c)\n",
    "    elif transform == \"vertical\":\n",
    "        return (2 - r, c)\n",
    "    elif transform == \"rotate90\":\n",
    "        return (c, 2 - r)\n",
    "    elif transform == \"rotate180\":\n",
    "        return (2 - r, 2 - c)\n",
    "    elif transform == \"rotate270\":\n",
    "        return (2 - c, r)\n",
    "    elif \"_\" in transform:\n",
    "        base, extra = transform.split(\"_\")\n",
    "        if base == \"rotate90\":\n",
    "            new = (c, 2 - r)\n",
    "        elif base == \"rotate180\":\n",
    "            new = (2 - r, 2 - c)\n",
    "        elif base == \"rotate270\":\n",
    "            new = (2 - c, r)\n",
    "        else:\n",
    "            new = (r, c)\n",
    "        if extra == \"horizontal\":\n",
    "            new = (new[0], 2 - new[1])\n",
    "        elif extra == \"vertical\":\n",
    "            new = (2 - new[0], new[1])\n",
    "        return new\n",
    "    else:\n",
    "        return (r, c)\n",
    "\n",
    "def transform_state(state: State, transform: str) -> State:\n",
    "    global_board = state.board.transpose(0, 2, 1, 3).reshape(9, 9)\n",
    "\n",
    "    if transform == \"identity\":\n",
    "        transformed_global_board = global_board.copy()\n",
    "    elif transform == \"horizontal\":\n",
    "        transformed_global_board = np.fliplr(global_board)\n",
    "    elif transform == \"vertical\":\n",
    "        transformed_global_board = np.flipud(global_board)\n",
    "    elif transform.startswith(\"rotate\"):\n",
    "        if \"_\" in transform:\n",
    "            base, extra = transform.split(\"_\")\n",
    "            if base == \"rotate90\":\n",
    "                k = 1\n",
    "            elif base == \"rotate180\":\n",
    "                k = 2\n",
    "            elif base == \"rotate270\":\n",
    "                k = 3\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown base rotation: {base}\")\n",
    "            transformed_global_board = np.rot90(global_board, k=k)\n",
    "            if extra == \"horizontal\":\n",
    "                transformed_global_board = np.fliplr(transformed_global_board)\n",
    "            elif extra == \"vertical\":\n",
    "                transformed_global_board = np.flipud(transformed_global_board)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown extra transform: {extra}\")\n",
    "        else:\n",
    "            if transform == \"rotate90\":\n",
    "                k = 1\n",
    "            elif transform == \"rotate180\":\n",
    "                k = 2\n",
    "            elif transform == \"rotate270\":\n",
    "                k = 3\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown rotation transform: {transform}\")\n",
    "            transformed_global_board = np.rot90(global_board, k=k)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown transform: {transform}\")\n",
    "\n",
    "    new_board = transformed_global_board.reshape(3, 3, 3, 3).transpose(0, 2, 1, 3)\n",
    "\n",
    "    new_prev = None\n",
    "    if state.prev_local_action is not None:\n",
    "        new_prev = update_prev_local_action(state.prev_local_action, transform)\n",
    "\n",
    "    return State(board=new_board, fill_num=state.fill_num, prev_local_action=new_prev)\n",
    "\n",
    "def augment_entire_state(state: State) -> list[State]:\n",
    "    transforms = [\n",
    "        \"identity\", \"horizontal\", \"vertical\",\n",
    "        \"rotate90\", \"rotate90_horizontal\", \"rotate90_vertical\",\n",
    "        \"rotate180\", \"rotate180_horizontal\", \"rotate180_vertical\",\n",
    "        \"rotate270\", \"rotate270_horizontal\", \"rotate270_vertical\"\n",
    "    ]\n",
    "    return [transform_state(state, t) for t in transforms]\n",
    "\n",
    "def state_to_key(state: State) -> tuple:\n",
    "    return (state.board.tobytes(), state.fill_num, state.prev_local_action)\n",
    "\n",
    "def augment_dataset(data: list[tuple[State, float]]) -> list[tuple[State, float]]:\n",
    "    augmented_data = []\n",
    "    for state, utility in data:\n",
    "        for aug_state in augment_entire_state(state):\n",
    "            augmented_data.append((aug_state, utility))\n",
    "\n",
    "    unique_data = {}\n",
    "    for state, utility in augmented_data:\n",
    "        key = state_to_key(state)\n",
    "        if key not in unique_data:\n",
    "            unique_data[key] = (state, utility)\n",
    "    return list(unique_data.values())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    original_data = load_data()\n",
    "    print(f\"Original data size: {len(original_data)}\")\n",
    "\n",
    "    augmented_data = augment_dataset(original_data)\n",
    "    print(f\"Augmented data size (duplicates removed): {len(augmented_data)}\")\n",
    "\n",
    "    augmented_data_for_saving = []\n",
    "    for state, utility in augmented_data:\n",
    "        row_data = (state.board, state.fill_num, state.prev_local_action)\n",
    "        augmented_data_for_saving.append((row_data, utility))\n",
    "\n",
    "    with open(\"augmented_data.pkl\", \"wb\") as f:\n",
    "        pickle.dump(augmented_data_for_saving, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af7ec2d",
   "metadata": {},
   "source": [
    "data augmentation including swapping player 1 and 2, 1276600 data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from utils import State, load_data\n",
    "\n",
    "def update_prev_local_action(prev: tuple, transform: str) -> tuple:\n",
    "    r, c = prev\n",
    "    if transform == \"identity\":\n",
    "        return (r, c)\n",
    "    elif transform == \"horizontal\":\n",
    "        return (r, 2 - c)\n",
    "    elif transform == \"vertical\":\n",
    "        return (2 - r, c)\n",
    "    elif transform == \"rotate90\":\n",
    "        return (c, 2 - r)\n",
    "    elif transform == \"rotate180\":\n",
    "        return (2 - r, 2 - c)\n",
    "    elif transform == \"rotate270\":\n",
    "        return (2 - c, r)\n",
    "    elif \"_\" in transform:\n",
    "        base, extra = transform.split(\"_\")\n",
    "        if base == \"rotate90\":\n",
    "            new = (c, 2 - r)\n",
    "        elif base == \"rotate180\":\n",
    "            new = (2 - r, 2 - c)\n",
    "        elif base == \"rotate270\":\n",
    "            new = (2 - c, r)\n",
    "        else:\n",
    "            new = (r, c)\n",
    "        if extra == \"horizontal\":\n",
    "            new = (new[0], 2 - new[1])\n",
    "        elif extra == \"vertical\":\n",
    "            new = (2 - new[0], new[1])\n",
    "        return new\n",
    "    else:\n",
    "        return (r, c)\n",
    "\n",
    "def transform_state(state: State, transform: str) -> State:\n",
    "    global_board = state.board.transpose(0, 2, 1, 3).reshape(9, 9)\n",
    "    if transform == \"identity\":\n",
    "        transformed_global_board = global_board.copy()\n",
    "    elif transform == \"horizontal\":\n",
    "        transformed_global_board = np.fliplr(global_board)\n",
    "    elif transform == \"vertical\":\n",
    "        transformed_global_board = np.flipud(global_board)\n",
    "    elif transform.startswith(\"rotate\"):\n",
    "        if \"_\" in transform:\n",
    "            base, extra = transform.split(\"_\")\n",
    "            k = {\"rotate90\": 1, \"rotate180\": 2, \"rotate270\": 3}.get(base, 0)\n",
    "            transformed_global_board = np.rot90(global_board, k=k)\n",
    "            if extra == \"horizontal\":\n",
    "                transformed_global_board = np.fliplr(transformed_global_board)\n",
    "            elif extra == \"vertical\":\n",
    "                transformed_global_board = np.flipud(transformed_global_board)\n",
    "        else:\n",
    "            k = {\"rotate90\": 1, \"rotate180\": 2, \"rotate270\": 3}.get(transform, 0)\n",
    "            transformed_global_board = np.rot90(global_board, k=k)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown transform: {transform}\")\n",
    "    new_board = transformed_global_board.reshape(3, 3, 3, 3).transpose(0, 2, 1, 3)\n",
    "    new_prev = update_prev_local_action(state.prev_local_action, transform) if state.prev_local_action else None\n",
    "    return State(board=new_board, fill_num=state.fill_num, prev_local_action=new_prev)\n",
    "\n",
    "def augment_entire_state(state: State) -> list[State]:\n",
    "    transforms = [\n",
    "        \"identity\", \"horizontal\", \"vertical\",\n",
    "        \"rotate90\", \"rotate90_horizontal\", \"rotate90_vertical\",\n",
    "        \"rotate180\", \"rotate180_horizontal\", \"rotate180_vertical\",\n",
    "        \"rotate270\", \"rotate270_horizontal\", \"rotate270_vertical\"\n",
    "    ]\n",
    "    return [transform_state(state, t) for t in transforms]\n",
    "\n",
    "def state_to_key(state: State) -> tuple:\n",
    "    return (state.board.tobytes(), state.fill_num, state.prev_local_action)\n",
    "\n",
    "def augment_dataset(data: list[tuple[State, float]]) -> list[tuple[State, float]]:\n",
    "    augmented_data = []\n",
    "    for state, utility in data:\n",
    "        for aug_state in augment_entire_state(state):\n",
    "            augmented_data.append((aug_state, utility))\n",
    "    unique_data = {}\n",
    "    for state, utility in augmented_data:\n",
    "        key = state_to_key(state)\n",
    "        if key not in unique_data:\n",
    "            unique_data[key] = (state, utility)\n",
    "    return list(unique_data.values())\n",
    "\n",
    "def swap_state(state: State) -> State:\n",
    "    new_board = np.where(state.board == 1, 2, np.where(state.board == 2, 1, state.board))\n",
    "    new_fill_num = 3 - state.fill_num\n",
    "    return State(board=new_board, fill_num=new_fill_num, prev_local_action=state.prev_local_action)\n",
    "\n",
    "def augment_dataset_with_swap(data: list[tuple[State, float]]) -> list[tuple[State, float]]:\n",
    "    swapped_data = []\n",
    "    for state, utility in data:\n",
    "        swapped_state = swap_state(state)\n",
    "        swapped_utility = -utility\n",
    "        swapped_data.append((swapped_state, swapped_utility))\n",
    "    unique_data = {}\n",
    "    for state, utility in swapped_data:\n",
    "        key = state_to_key(state)\n",
    "        if key not in unique_data:\n",
    "            unique_data[key] = (state, utility)\n",
    "    return list(unique_data.values())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    original_data = load_data()\n",
    "    print(f\"Original data size: {len(original_data)}\")\n",
    "    sym_augmented_data = augment_dataset(original_data)\n",
    "    print(f\"Symmetry-augmented data size (duplicates removed): {len(sym_augmented_data)}\")\n",
    "    swapped_augmented_data = augment_dataset_with_swap(sym_augmented_data)\n",
    "    print(f\"Swapped-augmented data size: {len(swapped_augmented_data)}\")\n",
    "    combined_data = sym_augmented_data + swapped_augmented_data\n",
    "    final_unique_data = {}\n",
    "    for state, utility in combined_data:\n",
    "        key = state_to_key(state)\n",
    "        if key not in final_unique_data:\n",
    "            final_unique_data[key] = (state, utility)\n",
    "    final_data = list(final_unique_data.values())\n",
    "    print(f\"Final augmented data size (combined and duplicates removed): {len(final_data)}\")\n",
    "    final_data_for_saving = []\n",
    "    for state, utility in final_data:\n",
    "        row_data = (state.board, state.fill_num, state.prev_local_action)\n",
    "        final_data_for_saving.append((row_data, utility))\n",
    "    with open(\"augmented_data2.pkl\", \"wb\") as f:\n",
    "        pickle.dump(final_data_for_saving, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75689da",
   "metadata": {},
   "source": [
    "load data from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafbf568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import State, Action\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_aug_data() -> list[tuple[State, float]]:\n",
    "    with open(\"augmented_data.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    new_data = []\n",
    "    for row in data:\n",
    "        row_data, utility = row\n",
    "        board, fill_num, prev_local_action = row_data\n",
    "        state = State(board=board, fill_num=fill_num, prev_local_action=prev_local_action)\n",
    "        new_data.append((state, utility))\n",
    "    return new_data\n",
    "\n",
    "data = load_aug_data()\n",
    "X_list = []\n",
    "y_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d2691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import State, Action\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(93, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "data = load_aug_data()\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for state, eval_value in data:\n",
    "    global_board_features = state.board.reshape(-1)\n",
    "    local_board_features = state.local_board_status.reshape(-1)\n",
    "    fill_num_feature = np.array([state.fill_num], dtype=np.float32)\n",
    "    if state.prev_local_action is None:\n",
    "        prev_action = np.array([-1, -1], dtype=np.float32)\n",
    "    else:\n",
    "        prev_action = np.array(state.prev_local_action, dtype=np.float32)\n",
    "    features = np.concatenate([global_board_features, local_board_features, fill_num_feature, prev_action])\n",
    "    X_list.append(features)\n",
    "    y_list.append(eval_value)\n",
    "\n",
    "X = torch.tensor(X_list, dtype=torch.float32)\n",
    "y = torch.tensor(y_list, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "X_train, X_eval = X_train.to(device), X_eval.to(device)\n",
    "y_train, y_eval = y_train.to(device), y_eval.to(device)\n",
    "\n",
    "net = Net().to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "loss_fn = nn.MSELoss()\n",
    "losses = []\n",
    "\n",
    "num_epochs = 1500\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    y_pred_train = net(X_train)\n",
    "    loss = loss_fn(y_pred_train, y_train)\n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_eval = net(X_eval)\n",
    "\n",
    "eval_mse = loss_fn(y_pred_eval, y_eval).item()\n",
    "print(f\"Evaluation MSE: {eval_mse:.4f}\")\n",
    "\n",
    "trained_weights = net.state_dict()\n",
    "with open(\"weights.txt\", \"w\") as f:\n",
    "    for name, param in trained_weights.items():\n",
    "        values = param.detach().cpu().numpy().tolist()\n",
    "        f.write(f\"{name.upper()} = {values}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9224ea1",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import State, Action\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for state, eval_value in data:\n",
    "    global_board_features = state.board.reshape(-1)\n",
    "    local_board_features = state.local_board_status.reshape(-1)\n",
    "    fill_num_feature = np.array([state.fill_num], dtype=np.float32)\n",
    "    if state.prev_local_action is None:\n",
    "        prev_action = np.array([-1, -1], dtype=np.float32)\n",
    "    else:\n",
    "        prev_action = np.array(state.prev_local_action, dtype=np.float32)\n",
    "    features = np.concatenate([global_board_features, local_board_features, fill_num_feature, prev_action])\n",
    "    X_list.append(features)\n",
    "    y_list.append(eval_value)\n",
    "\n",
    "X = torch.tensor(X_list, dtype=torch.float32)\n",
    "y = torch.tensor(y_list, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "num_epochs = 600\n",
    "for epoch in range(num_epochs):\n",
    "    fold_val_losses = []\n",
    "    for i in range(3):\n",
    "        indices = torch.randperm(X_train_full.size(0))\n",
    "        fold_size = int(0.2 * X_train_full.size(0))     \n",
    "        val_indices = indices[i * fold_size : (i + 1) * fold_size]\n",
    "        train_indices = torch.cat([indices[:i * fold_size], indices[(i + 1) * fold_size:]])\n",
    "\n",
    "        X_train_fold = X_train_full[train_indices].to(device)\n",
    "        y_train_fold = y_train_full[train_indices].to(device)\n",
    "        X_val_fold = X_train_full[val_indices].to(device)\n",
    "        y_val_fold = y_train_full[val_indices].to(device)\n",
    "\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred_train = net(X_train_fold)\n",
    "        loss_train = loss_fn(y_pred_train, y_train_fold)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_val = net(X_val_fold)\n",
    "            loss_val = loss_fn(y_pred_val, y_val_fold)\n",
    "            fold_val_losses.append(loss_val.item())\n",
    "\n",
    "    avg_val_loss = np.mean(fold_val_losses)\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Average Validation MSE: {avg_val_loss:.4f}\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = net(X_test)\n",
    "    test_loss = loss_fn(y_pred_test, y_test).item()\n",
    "    \n",
    "print(f\"\\nFinal Test MSE: {test_loss:.4f}\")\n",
    "\n",
    "trained_weights = net.state_dict()\n",
    "with open(\"weights.txt\", \"w\") as f:\n",
    "    for name, param in trained_weights.items():\n",
    "        values = param.detach().cpu().numpy().tolist()\n",
    "        f.write(f\"{name.upper()} = {values}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1299f943",
   "metadata": {},
   "source": [
    "one-hot encoding with 639004 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding load\n",
    "from utils import State, Action\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def load_aug_data() -> list[tuple[State, float]]:\n",
    "    with open(\"augmented_data.pkl\", \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    new_data = []\n",
    "    for row in data:\n",
    "        row_data, utility = row\n",
    "        board, fill_num, prev_local_action = row_data\n",
    "        state = State(board=board, fill_num=fill_num, prev_local_action=prev_local_action)\n",
    "        new_data.append((state, utility))\n",
    "    return new_data\n",
    "\n",
    "def custom_encode_2(val: int) -> np.ndarray:\n",
    "    if val == 0:\n",
    "        return np.array([0, 0], dtype=np.float32)\n",
    "    elif val == 1:\n",
    "        return np.array([0, 1], dtype=np.float32)\n",
    "    elif val == 2:\n",
    "        return np.array([1, 0], dtype=np.float32)\n",
    "    else:\n",
    "        raise ValueError(\"Value must be 0, 1, or 2.\")\n",
    "\n",
    "def custom_encode_status(val: int) -> np.ndarray:\n",
    "    if val == 0:\n",
    "        return np.array([0, 0, 0], dtype=np.float32)\n",
    "    elif val == 1:\n",
    "        return np.array([0, 0, 1], dtype=np.float32)\n",
    "    elif val == 2:\n",
    "        return np.array([0, 1, 0], dtype=np.float32)\n",
    "    elif val == 3:\n",
    "        return np.array([1, 0, 0], dtype=np.float32)\n",
    "    else:\n",
    "        raise ValueError(\"Local board status must be 0, 1, 2, or 3.\")\n",
    "\n",
    "def custom_encode_coord(val: int) -> np.ndarray:\n",
    "    if val < 0:\n",
    "        return np.array([0, 0], dtype=np.float32)\n",
    "    return custom_encode_2(val)\n",
    "\n",
    "data = load_aug_data()\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for state, eval_value in data:\n",
    "    board_flat = state.board.reshape(-1)\n",
    "    global_board_encoded = np.array([custom_encode_2(val) for val in board_flat])\n",
    "    global_board_features = global_board_encoded.flatten()\n",
    "\n",
    "    local_board_flat = state.local_board_status.reshape(-1)\n",
    "    local_board_encoded = np.array([custom_encode_status(val) for val in local_board_flat])\n",
    "    local_board_features = local_board_encoded.flatten()\n",
    "\n",
    "    fill_num_feature = custom_encode_2(state.fill_num)\n",
    "\n",
    "    if state.prev_local_action is None:\n",
    "        prev_r, prev_c = -1, -1\n",
    "    else:\n",
    "        prev_r, prev_c = state.prev_local_action\n",
    "    prev_r_enc = custom_encode_coord(prev_r)\n",
    "    prev_c_enc = custom_encode_coord(prev_c)\n",
    "    prev_action = np.concatenate([prev_r_enc, prev_c_enc])\n",
    "\n",
    "    features = np.concatenate([global_board_features, local_board_features, fill_num_feature, prev_action])\n",
    "    X_list.append(features)\n",
    "    y_list.append(eval_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e17036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "from utils import State, Action\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(195, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc_mid = nn.Linear(128, 64)\n",
    "        self.bn_mid = nn.BatchNorm1d(64)\n",
    "        self.dropout_mid = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn_mid(self.fc_mid(x)))\n",
    "        x = self.dropout_mid(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "X = torch.tensor(X_list, dtype=torch.float32)\n",
    "y = torch.tensor(y_list, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "X_train, X_eval = X_train.to(device), X_eval.to(device)\n",
    "y_train, y_eval = y_train.to(device), y_eval.to(device)\n",
    "\n",
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "losses = []\n",
    "\n",
    "num_epochs = 450\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    y_pred_train = net(X_train)\n",
    "    loss = loss_fn(y_pred_train, y_train)\n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_eval = net(X_eval)\n",
    "\n",
    "eval_mse = loss_fn(y_pred_eval, y_eval).item()\n",
    "print(f\"Evaluation MSE: {eval_mse:.4f}\")\n",
    "\n",
    "trained_weights = net.state_dict()\n",
    "weights_dict = OrderedDict()\n",
    "for name, param in trained_weights.items():\n",
    "    values = param.detach().cpu().numpy().tolist()\n",
    "    weights_dict[name] = values\n",
    "\n",
    "with open(\"weights.py\", \"w\") as f:\n",
    "    f.write(\"weights = OrderedDict([\\n\")\n",
    "    for key, value in weights_dict.items():\n",
    "        f.write(f\"    ('{key}', torch.tensor(\\n\")\n",
    "        f.write(pprint.pformat(value, indent=8))\n",
    "        f.write(\"\\n    )),\\n\")\n",
    "    f.write(\"])\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc10b2e9",
   "metadata": {},
   "source": [
    "splitting dataset before augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7916dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from utils import State, load_data\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def update_prev_local_action(prev: tuple, transform: str) -> tuple:\n",
    "    r, c = prev\n",
    "    if transform == \"identity\":\n",
    "        return (r, c)\n",
    "    elif transform == \"horizontal\":\n",
    "        return (r, 2 - c)\n",
    "    elif transform == \"vertical\":\n",
    "        return (2 - r, c)\n",
    "    elif transform == \"rotate90\":\n",
    "        return (c, 2 - r)\n",
    "    elif transform == \"rotate180\":\n",
    "        return (2 - r, 2 - c)\n",
    "    elif transform == \"rotate270\":\n",
    "        return (2 - c, r)\n",
    "    elif \"_\" in transform:\n",
    "        base, extra = transform.split(\"_\")\n",
    "        if base == \"rotate90\":\n",
    "            new = (c, 2 - r)\n",
    "        elif base == \"rotate180\":\n",
    "            new = (2 - r, 2 - c)\n",
    "        elif base == \"rotate270\":\n",
    "            new = (2 - c, r)\n",
    "        else:\n",
    "            new = (r, c)\n",
    "        if extra == \"horizontal\":\n",
    "            new = (new[0], 2 - new[1])\n",
    "        elif extra == \"vertical\":\n",
    "            new = (2 - new[0], new[1])\n",
    "        return new\n",
    "    else:\n",
    "        return (r, c)\n",
    "\n",
    "def transform_state(state: State, transform: str) -> State:\n",
    "    global_board = state.board.transpose(0, 2, 1, 3).reshape(9, 9)\n",
    "\n",
    "    if transform == \"identity\":\n",
    "        transformed_global_board = global_board.copy()\n",
    "    elif transform == \"horizontal\":\n",
    "        transformed_global_board = np.fliplr(global_board)\n",
    "    elif transform == \"vertical\":\n",
    "        transformed_global_board = np.flipud(global_board)\n",
    "    elif transform.startswith(\"rotate\"):\n",
    "        if \"_\" in transform:\n",
    "            base, extra = transform.split(\"_\")\n",
    "            if base == \"rotate90\":\n",
    "                k = 1\n",
    "            elif base == \"rotate180\":\n",
    "                k = 2\n",
    "            elif base == \"rotate270\":\n",
    "                k = 3\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown base rotation: {base}\")\n",
    "            transformed_global_board = np.rot90(global_board, k=k)\n",
    "            if extra == \"horizontal\":\n",
    "                transformed_global_board = np.fliplr(transformed_global_board)\n",
    "            elif extra == \"vertical\":\n",
    "                transformed_global_board = np.flipud(transformed_global_board)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown extra transform: {extra}\")\n",
    "        else:\n",
    "            if transform == \"rotate90\":\n",
    "                k = 1\n",
    "            elif transform == \"rotate180\":\n",
    "                k = 2\n",
    "            elif transform == \"rotate270\":\n",
    "                k = 3\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown rotation transform: {transform}\")\n",
    "            transformed_global_board = np.rot90(global_board, k=k)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown transform: {transform}\")\n",
    "\n",
    "    new_board = transformed_global_board.reshape(3, 3, 3, 3).transpose(0, 2, 1, 3)\n",
    "    new_prev = None\n",
    "    if state.prev_local_action is not None:\n",
    "        new_prev = update_prev_local_action(state.prev_local_action, transform)\n",
    "\n",
    "    return State(board=new_board, fill_num=state.fill_num, prev_local_action=new_prev)\n",
    "\n",
    "def augment_entire_state(state: State) -> list[State]:\n",
    "    transforms = [\n",
    "        \"identity\", \"horizontal\", \"vertical\",\n",
    "        \"rotate90\", \"rotate90_horizontal\", \"rotate90_vertical\",\n",
    "        \"rotate180\", \"rotate180_horizontal\", \"rotate180_vertical\",\n",
    "        \"rotate270\", \"rotate270_horizontal\", \"rotate270_vertical\"\n",
    "    ]\n",
    "    return [transform_state(state, t) for t in transforms]\n",
    "\n",
    "def state_to_key(state: State) -> tuple:\n",
    "    return (state.board.tobytes(), state.fill_num, state.prev_local_action)\n",
    "\n",
    "def augment_dataset(data: list[tuple[State, float]]) -> list[tuple[State, float]]:\n",
    "    augmented_data = []\n",
    "    for state, utility in data:\n",
    "        for aug_state in augment_entire_state(state):\n",
    "            augmented_data.append((aug_state, utility))\n",
    "    unique_data = {}\n",
    "    for state, utility in augmented_data:\n",
    "        key = state_to_key(state)\n",
    "        if key not in unique_data:\n",
    "            unique_data[key] = (state, utility)\n",
    "    return list(unique_data.values())\n",
    "\n",
    "def swap_state(state: State) -> State:\n",
    "    new_board = np.where(state.board == 1, 2, np.where(state.board == 2, 1, state.board))\n",
    "    new_fill_num = 3 - state.fill_num\n",
    "    return State(board=new_board, fill_num=new_fill_num, prev_local_action=state.prev_local_action)\n",
    "\n",
    "def augment_dataset_with_swap(data: list[tuple[State, float]]) -> list[tuple[State, float]]:\n",
    "    swapped_data = []\n",
    "    for state, utility in data:\n",
    "        swapped_state = swap_state(state)\n",
    "        swapped_utility = -utility\n",
    "        swapped_data.append((swapped_state, swapped_utility))\n",
    "    \n",
    "    unique_data = {}\n",
    "    for state, utility in swapped_data:\n",
    "        key = state_to_key(state)\n",
    "        if key not in unique_data:\n",
    "            unique_data[key] = (state, utility)\n",
    "    return list(unique_data.values())\n",
    "\n",
    "def custom_encode_2(val: int) -> np.ndarray:\n",
    "    if val == 0:\n",
    "        return np.array([0, 0], dtype=np.float32)\n",
    "    elif val == 1:\n",
    "        return np.array([0, 1], dtype=np.float32)\n",
    "    elif val == 2:\n",
    "        return np.array([1, 0], dtype=np.float32)\n",
    "    else:\n",
    "        raise ValueError(\"Value must be 0, 1, or 2.\")\n",
    "\n",
    "def custom_encode_status(val: int) -> np.ndarray:\n",
    "    if val == 0:\n",
    "        return np.array([0, 0, 0], dtype=np.float32)\n",
    "    elif val == 1:\n",
    "        return np.array([0, 0, 1], dtype=np.float32)\n",
    "    elif val == 2:\n",
    "        return np.array([0, 1, 0], dtype=np.float32)\n",
    "    elif val == 3:\n",
    "        return np.array([1, 0, 0], dtype=np.float32)\n",
    "    else:\n",
    "        raise ValueError(\"Local board status must be 0, 1, 2, or 3.\")\n",
    "\n",
    "def custom_encode_coord(val: int) -> np.ndarray:\n",
    "    if val < 0:\n",
    "        return np.array([0, 0], dtype=np.float32)\n",
    "    return custom_encode_2(val)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    original_data = load_data()\n",
    "    print(f\"Original data size: {len(original_data)}\")\n",
    "\n",
    "    train_data, test_data = train_test_split(original_data, test_size=0.15, random_state=42)\n",
    "    print(f\"Train data size: {len(train_data)} | Test data size: {len(test_data)}\")\n",
    "\n",
    "    sym_aug_train = augment_dataset(train_data)\n",
    "    swap_aug_train = augment_dataset_with_swap(sym_aug_train)\n",
    "    combined_train = sym_aug_train + swap_aug_train\n",
    "    unique_train = {}\n",
    "    for state, utility in combined_train:\n",
    "        key = state_to_key(state)\n",
    "        if key not in unique_train:\n",
    "            unique_train[key] = (state, utility)\n",
    "    final_train = list(unique_train.values())\n",
    "    print(f\"Final augmented train data size: {len(final_train)}\")\n",
    "\n",
    "    sym_aug_test = augment_dataset(test_data)\n",
    "    swap_aug_test = augment_dataset_with_swap(sym_aug_test)\n",
    "    combined_test = sym_aug_test + swap_aug_test\n",
    "    unique_test = {}\n",
    "    for state, utility in combined_test:\n",
    "        key = state_to_key(state)\n",
    "        if key not in unique_test:\n",
    "            unique_test[key] = (state, utility)\n",
    "    final_test = list(unique_test.values())\n",
    "    print(f\"Final augmented test data size: {len(final_test)}\")\n",
    "\n",
    "    def extract_features(state: State) -> np.ndarray:\n",
    "        board_flat = state.board.reshape(-1)\n",
    "        global_board_encoded = np.array([custom_encode_2(val) for val in board_flat])\n",
    "        global_board_features = global_board_encoded.flatten()\n",
    "\n",
    "        local_board_flat = state.local_board_status.reshape(-1)\n",
    "        local_board_encoded = np.array([custom_encode_status(val) for val in local_board_flat])\n",
    "        local_board_features = local_board_encoded.flatten()\n",
    "\n",
    "        fill_num_feature = custom_encode_2(state.fill_num)\n",
    "\n",
    "        if state.prev_local_action is None:\n",
    "            prev_r, prev_c = -1, -1\n",
    "        else:\n",
    "            prev_r, prev_c = state.prev_local_action\n",
    "        prev_r_enc = custom_encode_coord(prev_r)\n",
    "        prev_c_enc = custom_encode_coord(prev_c)\n",
    "        prev_action = np.concatenate([prev_r_enc, prev_c_enc])\n",
    "\n",
    "        features = np.concatenate([global_board_features, local_board_features, fill_num_feature, prev_action])\n",
    "        return features\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for state, utility in final_train:\n",
    "        features = extract_features(state)\n",
    "        X_train.append(features)\n",
    "        y_train.append(utility)\n",
    "\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for state, utility in final_test:\n",
    "        features = extract_features(state)\n",
    "        X_test.append(features)\n",
    "        y_test.append(utility)\n",
    "\n",
    "    data = {\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "    with open(\"features15.pkl\", \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9815eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"features15.pkl\", \"rb\") as f:\n",
    "    data_loaded = pickle.load(f)\n",
    "\n",
    "X_train = data_loaded['X_train']\n",
    "y_train = data_loaded['y_train']\n",
    "X_eval = data_loaded['X_test']\n",
    "y_eval = data_loaded['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import pprint\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(195, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc_mid = nn.Linear(128, 64)\n",
    "        self.bn_mid = nn.BatchNorm1d(64)\n",
    "        self.dropout_mid = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn_mid(self.fc_mid(x)))\n",
    "        x = self.dropout_mid(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_eval_tensor = torch.tensor(X_eval, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "y_eval_tensor = torch.tensor(y_eval, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "losses = []\n",
    "\n",
    "num_epochs = 1200\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    y_pred_train = net(X_train_tensor)\n",
    "    loss = loss_fn(y_pred_train, y_train_tensor)\n",
    "    losses.append(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}\")\n",
    "    if epoch + 1 == num_epochs:\n",
    "        print(f\"Epoch {num_epochs}, Training Loss: {loss.item():.4f}\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_eval = net(X_eval_tensor)\n",
    "eval_mse = loss_fn(y_pred_eval, y_eval_tensor).item()\n",
    "print(f\"Evaluation MSE: {eval_mse:.4f}\")\n",
    "\n",
    "trained_weights = net.state_dict()\n",
    "weights_dict = OrderedDict()\n",
    "for name, param in trained_weights.items():\n",
    "    values = param.detach().cpu().numpy().tolist()\n",
    "    weights_dict[name] = values\n",
    "\n",
    "with open(\"weights.py\", \"w\") as f:\n",
    "    f.write(\"weights = OrderedDict([\\n\")\n",
    "    for key, value in weights_dict.items():\n",
    "        f.write(f\"    ('{key}', torch.tensor(\\n\")\n",
    "        f.write(pprint.pformat(value, indent=8))\n",
    "        f.write(\"\\n    )),\\n\")\n",
    "    f.write(\"])\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
